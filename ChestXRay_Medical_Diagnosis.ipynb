{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26bed201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-14 10:21:20.692086: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-14 10:21:20.757722: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-14 10:21:22.366649: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/le-cuong/Desktop/BTL_Machine_Learning/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import time\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import cv2\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac4bc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c19aa0",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "- We chose the chest-x-ray datasets from Kaggle: https://www.kaggle.com/datasets/habibmrad1983/chestxray8-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc86429b",
   "metadata": {},
   "source": [
    "#### Split dataset into train dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5624a8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 99316 rows and 16 columns in the train data frame\n",
      "              Image  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
      "0  00000001_000.png            0             1              0      0   \n",
      "1  00000001_001.png            0             1              0      0   \n",
      "2  00000001_002.png            0             1              0      0   \n",
      "3  00000002_000.png            0             0              0      0   \n",
      "4  00000004_000.png            0             0              0      0   \n",
      "\n",
      "   Effusion  Emphysema  Fibrosis  Hernia  Infiltration  Mass  Nodule  \\\n",
      "0         0          0         0       0             0     0       0   \n",
      "1         0          1         0       0             0     0       0   \n",
      "2         1          0         0       0             0     0       0   \n",
      "3         0          0         0       0             0     0       0   \n",
      "4         0          0         0       0             0     1       1   \n",
      "\n",
      "   PatientId  Pleural_Thickening  Pneumonia  Pneumothorax  \n",
      "0          1                   0          0             0  \n",
      "1          1                   0          0             0  \n",
      "2          1                   0          0             0  \n",
      "3          2                   0          0             0  \n",
      "4          4                   0          0             0  \n",
      "\n",
      "\n",
      "There are 5672 rows and 16 columns in the train data frame\n",
      "              Image  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
      "0  00000009_000.png            0             0              0      0   \n",
      "1  00000011_000.png            0             0              0      0   \n",
      "2  00000011_001.png            0             0              0      0   \n",
      "3  00000011_002.png            0             0              0      0   \n",
      "4  00000011_003.png            0             0              0      0   \n",
      "\n",
      "   Effusion  Emphysema  Fibrosis  Hernia  Infiltration  Mass  Nodule  \\\n",
      "0         0          1         0       0             0     0       0   \n",
      "1         1          0         0       0             0     0       0   \n",
      "2         0          0         0       0             0     0       0   \n",
      "3         0          0         0       0             0     0       0   \n",
      "4         0          0         0       0             0     0       0   \n",
      "\n",
      "   PatientId  Pleural_Thickening  Pneumonia  Pneumothorax  \n",
      "0          9                   0          0             0  \n",
      "1         11                   0          0             0  \n",
      "2         11                   0          0             0  \n",
      "3         11                   0          0             0  \n",
      "4         11                   0          0             0  \n"
     ]
    }
   ],
   "source": [
    "# Read csv-file\n",
    "df = pd.read_csv(\"data/train-all.csv\")\n",
    "valid_df = pd.read_csv(\"data/valid-all.csv\")\n",
    "print(f'There are {df.shape[0]} rows and {df.shape[1]} columns in the train data frame')\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f'There are {valid_df.shape[0]} rows and {valid_df.shape[1]} columns in the train data frame')\n",
    "print(valid_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51c5b913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toàn bộ: 99316 ảnh\n",
      "Train:   79452 ảnh (80.0%)\n",
      "Test:    19864 ảnh (20.0%)\n",
      "\n",
      "Đã lưu thành công 2 files: train.csv, test.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=test_size,\n",
    "    random_state=42\n",
    "    # stratify=df['Finding Labels']\n",
    ")\n",
    "\n",
    "print(f\"Toàn bộ: {len(df)} ảnh\")\n",
    "print(f\"Train:   {len(train_df)} ảnh ({len(train_df)/len(df):.1%})\")\n",
    "print(f\"Test:    {len(test_df)} ảnh ({len(test_df)/len(df):.1%})\")\n",
    "\n",
    "train_df.to_csv('data/train.csv', index=False)\n",
    "test_df.to_csv('data/test.csv', index=False)\n",
    "\n",
    "print(\"\\nĐã lưu thành công 2 files: train.csv, test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a2b47",
   "metadata": {},
   "source": [
    "#### Prevent Data Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c7f6041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_leakage(df1, df2, patient_col):\n",
    "    \"\"\"\n",
    "    Return True if there any patients are in both df1 and df2.\n",
    "\n",
    "    Args:\n",
    "        df1 (dataframe): dataframe describing first dataset\n",
    "        df2 (dataframe): dataframe describing second dataset\n",
    "        patient_col (str): string name of column with patient IDs\n",
    "    \n",
    "    Returns:\n",
    "        leakage (bool): True if there is leakage, otherwise False\n",
    "    \"\"\"\n",
    "\n",
    "    df1_patients_unique = set(df1[patient_col])\n",
    "    df2_patients_unique = set(df2[patient_col])\n",
    "\n",
    "    patients_in_both_groups = list(df1_patients_unique.intersection(df2_patients_unique))\n",
    "\n",
    "    leakage = len(patients_in_both_groups) > 0\n",
    "\n",
    "    return leakage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
